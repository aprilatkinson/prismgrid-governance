# PrismGrid AI Governance & Compliance Position (MVP)

## Purpose

PrismGrid is designed for **Responsible AI operation in enterprise environments**.

It is built to reduce hallucinated authority, execution risk, and audit ambiguity in AI-driven systems.

---

## EU AI Act Risk Classification

PrismGrid qualifies as:

**Limited Risk / Minimal Risk (EU AI Act)**

Why:
- No autonomous decision-making
- No execution authority
- No behavioral manipulation
- No profiling of individuals
- No learning from outcomes

PrismGrid produces **decision-support diagnostics only**.

---

## Governance Safeguards

PrismGrid enforces:

- Deterministic outputs for identical inputs
- Immutable diagnostic artifacts
- Explicit evidence lineage
- Clear refusal and uncertainty signaling
- Strict separation between diagnosis, interpretation, and planning

---

## Prohibited Uses

PrismGrid must not be used as:
- legal advice
- regulatory certification
- proof of wrongdoing
- compliance clearance
- performance guarantee

---

## Human-in-the-Loop

PrismGrid always requires:
- human interpretation
- human execution decisions
- human accountability

Authority never transfers to the system.

---

## Why This Matters

Most AI failures occur when:
> “The AI said so” becomes a justification.

PrismGrid exists to prevent that failure mode.

---

### Scope Note

This document states PrismGrid’s governance position at a high level.

For the full AI governance framework, safeguards, and explicit EU AI Act risk mapping,
see:

docs/public/ai-governance-and-eu-ai-act.md

